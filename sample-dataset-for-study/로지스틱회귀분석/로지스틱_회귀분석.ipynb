{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "로지스틱 회귀분석.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwBeRXuSlefd"
      },
      "source": [
        "[데이터 셋 링크](https://github.com/rlagksqls17/repo_dataset/tree/master/sample-dataset-for-study/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Um9g_5c3n1z"
      },
      "source": [
        "# 로지스틱 회귀모델 이론과 설명   \n",
        "\n",
        "출처 1: ADP 실기 데이터 분석 전문가(데이터 에듀)\n",
        "출처 2: 빅데이터 분석기사 실기(데이터 캠퍼스)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jttbFDXR3sJa"
      },
      "source": [
        "로지스틱 회귀분석은 종속변수가 범주형 자료일 경우 적용하는 회귀모델이다.  \n",
        "\n",
        "범주형 자료에 선형회귀모델을 적용하면 문제가 발생하는데, 로지스틱회귀분석모델은 범주형 레이블 자료를 변형하여 비율로 적용한다.   \n",
        "\n",
        "이렇게 자료를 변형하면 독립변수의 변화에 따라 종속변수의 발생 비율에 어떤 경향이 존재하는데 이러한 곡선을 로지스틱 회귀모델이라 한다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWJ6TXToJndm"
      },
      "source": [
        "## 분석데이터 준비 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYVYW7_A2_bt"
      },
      "source": [
        " \"\"\"\n",
        "위스콘신 대학의 'breast-cancer-wisconsin.csv' 파일로 암예측분류를 진행해보도록 하겠습니다.  \n",
        "아래와 같이 데이터를 불러와 특성치(X)와 레이블(y) 데이터셋을 나눕니다.  \n",
        "\"\"\"\n",
        "\n",
        "# 분석결과 외 다른 문장이 뜨지 않도록 하는 코드  \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd  \n",
        "data = pd.read_csv(\"/content/sample_data/breast-cancer-wisconsin.csv\", encoding='utf-8')\n",
        "\n",
        "# 특성치\n",
        "X = data.iloc[:, 1:10]\n",
        "\n",
        "# 레이블\n",
        "y = data[[\"Class\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "kp0_NyZmtKly",
        "outputId": "d4547fe8-19d8-4521-e3c6-e143ba959dae"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>Clump_Thickness</th>\n",
              "      <th>Cell_Size</th>\n",
              "      <th>Cell_Shape</th>\n",
              "      <th>Marginal_Adhesion</th>\n",
              "      <th>Single_Epithelial_Cell_Size</th>\n",
              "      <th>Bare_Nuclei</th>\n",
              "      <th>Bland_Chromatin</th>\n",
              "      <th>Normal_Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1017122</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1018099</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1018561</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1033078</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1033078</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      code  Clump_Thickness  Cell_Size  ...  Normal_Nucleoli  Mitoses  Class\n",
              "0  1000025                5          1  ...                1        1      0\n",
              "1  1002945                5          4  ...                2        1      0\n",
              "2  1015425                3          1  ...                1        1      0\n",
              "3  1016277                6          8  ...                7        1      0\n",
              "4  1017023                4          1  ...                1        1      0\n",
              "5  1017122                8         10  ...                7        1      1\n",
              "6  1018099                1          1  ...                1        1      0\n",
              "7  1018561                2          1  ...                1        1      0\n",
              "8  1033078                2          1  ...                1        5      0\n",
              "9  1033078                4          2  ...                1        1      0\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1U4vjqFEDx2"
      },
      "source": [
        "\"\"\"\n",
        "train_test_split으로 train_data 셋과 test_data 셋을 분리합니다.  \n",
        "기본 디폴트 7:3 비율로 나누고, y 범주의 비율에 따라 분리되도록 stratify=y 옵션을 둡니다.  \n",
        "\"\"\"  \n",
        "\n",
        "from sklearn.model_selection import train_test_split  \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yiRrGTIHr4V"
      },
      "source": [
        "\"\"\"\n",
        "MinMaxScaler를 사용하여 최소 0, 최대 1이 되도록 정규화를 합니다.  \n",
        "X_train의 최소/최댓값을 기준으로 삼고 (fit), X_train과 X_test 데이터 셋을 변환 (transform) 합니다.  \n",
        "\"\"\"\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler  \n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_scaled_train = scaler.transform(X_train)\n",
        "X_scaled_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW-IeXuCJpqx"
      },
      "source": [
        "## 기본모델 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFFovcJzJhFE",
        "outputId": "5a69e1c1-1d4c-4116-fd25-a3bdd7d0d3ab"
      },
      "source": [
        "# 우선 하이퍼파라미터 C = 1인 기본 디폴트로 분석을 해보도록 하겠습니다.  \n",
        "# LogisticRegression을 불러와 model로 설정하고 훈련데이터에 fit 합니다.    \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_reg_model = LogisticRegression()\n",
        "logistic_reg_model.fit(X_scaled_train, y_train)\n",
        "\n",
        "# 그리고 예측치를 pred_train에 저장하고 model.score로 정확도를 살펴봅니다.  \n",
        "pred_train = logistic_reg_model.predict(X_scaled_train)\n",
        "\n",
        "# X_scaled_train으로 예측한 예측치와 y_train을 비교하여 score를 냅니다.  \n",
        "logistic_reg_model.score(X_scaled_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97265625"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT480VzZLxg1",
        "outputId": "cbae02fc-9b19-4499-83db-ec21e35ac864"
      },
      "source": [
        "# 오차행렬을 확인해봅시다.  \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 예측치와 실제 데이터 간의 오차 행렬을 확인합니다.\n",
        "confusion_train = confusion_matrix(y_train, pred_train)\n",
        "\n",
        "print(f\"오차행렬 : \\n {confusion_train}\")\n",
        "print(\"----------------------------------\")\n",
        "print(\"정상 중 5명이 오분류, 환자 중 9명이 오분류입니다.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차행렬 : \n",
            " [[328   5]\n",
            " [  9 170]]\n",
            "----------------------------------\n",
            "정상 중 5명이 오분류, 환자 중 9명이 오분류입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWguYZLYMmlk",
        "outputId": "eac3b1a3-10ed-478b-813e-0888435a9656"
      },
      "source": [
        "# 정밀도와 재현율은 각각 0.97, 0.98로 좋은 수준을 나타냅니다.  \n",
        "from sklearn.metrics import classification_report  \n",
        "\n",
        "cfreport_train = classification_report(y_train, pred_train)\n",
        "print(cfreport_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       333\n",
            "           1       0.97      0.95      0.96       179\n",
            "\n",
            "    accuracy                           0.97       512\n",
            "   macro avg       0.97      0.97      0.97       512\n",
            "weighted avg       0.97      0.97      0.97       512\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wjk3FpPNE3a",
        "outputId": "4e687fd8-e75a-4ea5-8844-09d11af331a5"
      },
      "source": [
        "# 테스트 데이터의 예측 결과도 저장해보고 정확도를 확인해봅시다.  \n",
        "pred_test = logistic_reg_model.predict(X_scaled_test)\n",
        "\n",
        "logistic_reg_model.score(X_scaled_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9590643274853801"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVBnG0RZNg2M",
        "outputId": "1831f3e3-2155-4554-cd5f-984f10a4b40d"
      },
      "source": [
        "# 마찬가지로 테스트 데이터에서 로지스틱회귀모형을 적용했을 때 오차행렬을 확인해봅시다.  \n",
        "confusion_test = confusion_matrix(y_test, pred_test)\n",
        "confusion_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[106,   5],\n",
              "       [  2,  58]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FwFRZ21Ny4r",
        "outputId": "b9dfd396-9494-48cc-cb72-31306d30023f"
      },
      "source": [
        "# 테스트 데이터 셋의 평가지표도 확인해봅시다.  \n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "logistic_test_CR = classification_report(y_test, pred_test)\n",
        "print(logistic_test_CR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.97       111\n",
            "           1       0.92      0.97      0.94        60\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.95      0.96      0.96       171\n",
            "weighted avg       0.96      0.96      0.96       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFOa94ivOSOI"
      },
      "source": [
        "## Grid Search  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41UKd3-SOZ7M",
        "outputId": "67621420-13e2-4e9d-e51f-a99f55aad562"
      },
      "source": [
        "\"\"\"\n",
        "이번엔 하이퍼파라미터인 C값을 조정하면서 좀 더 좋은 예측 모델을 탐색해보도록 하겠습니다.  \n",
        "다만 기본모델의 정확도가 워낙 높아 모델 개선의 여지는 많지 않을 것 같습니다.  \n",
        "아래와 같이 C를 0.001, 0.01, 0.1, 1, 10, 100 등 6개로 설정하고 그리드 탐색을 진행합니다.\n",
        "\"\"\"\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'C' : [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid_search.fit(X_scaled_train, y_train)\n",
        "\n",
        "print(f\"Best Parameter : {grid_search.best_params_}\")\n",
        "print(f\"Best Score : {grid_search.best_score_}\")\n",
        "print(f\"TestSet Score : {grid_search.score(X_scaled_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameter : {'C': 10}\n",
            "Best Score : 0.972606129830573\n",
            "TestSet Score : 0.9590643274853801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmGh8BiVR41J"
      },
      "source": [
        "## Random Search  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzg_JC61R4ZO",
        "outputId": "1aea9415-7c6a-4bc7-effa-4e40896c6bff"
      },
      "source": [
        "\"\"\"\n",
        "랜덤 탐색은 분석자가 하이퍼파라미터의 범위를 지정하고 그 안에서 무작위로 뽑아 수행하는 것입니다.  \n",
        "따라서 분석할 때마다 다른 결과가 나타날 수 있습니다.  \n",
        "\"\"\"  \n",
        "\n",
        "from scipy.stats import randint  \n",
        "param_distribs = {'C' : randint(low=0.001, high=100)}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(LogisticRegression(), \n",
        "                                   param_distributions=param_distribs, n_iter=100, cv=5)\n",
        "random_search.fit(X_scaled_train, y_train)\n",
        "\n",
        "print(f\"Best Parameter: {random_search.best_params_}\")\n",
        "print(f\"Best Score: {random_search.best_score_}\")\n",
        "print(f\"TestSet Score: {random_search.score(X_scaled_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameter: {'C': 11}\n",
            "Best Score: 0.9745478774033887\n",
            "TestSet Score: 0.9590643274853801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsrN_wPvozwn"
      },
      "source": [
        "# 로지스틱 회귀모델 개인 데이터 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Gsp2Txo2j-",
        "outputId": "c795df0e-348d-47a1-a6c3-0838ce458b81"
      },
      "source": [
        "import pandas as pd  \n",
        "from sklearn.model_selection import train_test_split  \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 데이터 불러오기\n",
        "credit = pd.read_csv(\"/content/sample_data/credit_final.csv\", encoding='utf-8')\n",
        "\n",
        "# 데이터 칼럼 설정 : 변수 선택 [1, 2, 3, 4, 6, 8, 9, 10, 12, 13, 14, 15, 20]\n",
        "X = credit.iloc[:, 1:]\n",
        "y = credit['credit.rating']\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = MinMaxScaler()  \n",
        "scaler.fit(X_train)\n",
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "# 로지스틱 모델 적용 \n",
        "LR_model = LogisticRegression()\n",
        "LR_model.fit(scaled_X_train, y_train)\n",
        "\n",
        "pred_train = LR_model.predict(scaled_X_train)\n",
        "pred_test = LR_model.predict(scaled_X_test)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "정확도 분석\n",
        "# LR_model.score(scaled_X_train, y_train) # 0.776 (컬럼 제거 후 0.774)\n",
        "# LR_model.score(scaled_X_test, y_test) # 0.78 (컬럼 제거 후 0.768)\n",
        "\"\"\"  \n",
        "\n",
        "\"\"\"\n",
        "혼동행렬 분석  \n",
        "# confusion_train = confusion_matrix(y_train, pred_train)\n",
        "array([[105, 120],\n",
        "       [ 48, 477]])\n",
        "# confusion_test = confusion_matrix(y_test, pred_test)\n",
        "array([[ 38,  37],\n",
        "       [ 18, 157]])\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.metrics import classification_report  \n",
        "\n",
        "cfreport_train = classification_report(y_train, pred_train)\n",
        "\n",
        "# 정확도 외에 정밀도(precision), 재현율(recall), f1-score 등이 제시된다.\n",
        "print(\"분류예측 레포트 : \\n\", cfreport_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분류예측 레포트 : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.47      0.56       225\n",
            "           1       0.80      0.91      0.85       525\n",
            "\n",
            "    accuracy                           0.78       750\n",
            "   macro avg       0.74      0.69      0.70       750\n",
            "weighted avg       0.77      0.78      0.76       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "17bNxry8H3dV",
        "outputId": "377a062e-ece9-44e9-d1e9-5f65d9d72411"
      },
      "source": [
        "credit.boxplot(column='age')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af6961910>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}